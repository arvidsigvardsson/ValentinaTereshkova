#+OPTIONS: html-postamble:nil
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
# #+HTML_HEAD: <link rel="stylesheet" type="text/css" href=org-style.css"
* Teknisk dagbok - Projekt VT 2017
  /Arvid Sigvardsson/
** 2017-04-03
*** Teknologier
    Vi brainstormade olika ideer till postitioneringssystem:
    1. Ultraljud
    2. Ultra wide band
    3. Snöre som roboten drar ut, vinkeln och längden bestämmer postitionen
    4. Projicerat färgspektrum
    5. RFID-taggar utplacerade i golvet
    6. INS, inertial navigation system
*** Indelning och systematisering
     (1) och (2) är trianguleringsmetoder, medan de andra innebär någon form av fysisk lokalisering. Vi gjorde åtskillnad på centraliserade och decentraliserade system. I de centrala systemen fastställs postitionen centralt av systemet, inte "ombord" på roboten. Detta kräver någon form av trådlös kommunikation till en modul på roboten, t ex wifi eller bluetooth. De decentraliserade lösningarna räknar ut positionen direkt i modulen på roboten.
*** Andra alternativ 
    Vi diskuterade även möjligheten att använda en/flera kameror och utföra någon bildbehandling. En variant är att ha en överblicksbild och indela bilden i ett rutnät. Annan variant är att använda kamera för triangulering. Alla vi i gruppen är lite skeptiska till kameraideerna, lite oklart varför.
*** Två stycken lösningar
    Det lutar åt att vi försöker oss på två lösningar som vi arbetar med parallellt, en enklare och en mer avancerad/noggrann. Delvis för att kunna leverera något system i god tid för plattformsgrupperna att testa, men fortfarande kunna leverera ett noggrant system. Delvis för att ha redundancy, om ett system inte fungerar så kan vi använda det andra.
*** Orientering
    Det är inte helt klart i vår uppgiftsbeskrivning om vi ska leverera ett system som räknar ut robotens orientering, alltså i vilken riktning den tittar/kör. Det är klart att det är något som krävs för att klara uppgiften, men det kan vara så att plattformsgrupperna ska hantera detta själva. Jag/vi lutar åt att det är något vi ska utföra. Jag ser tre lösningar på problemet:
    - gyroskop, tangerar INS ovan
    - ultraljud med två mikrofoner, och mäta fasskillnad (?) mellan dem
    - räkna ut orientering mha bildbehandling
*** Kommunikationsprotokoll
    Vi diskuterade med plattformsgrupperna att vi behöver bestämma hur vår positioneringsmodul ska kommunicera med deras styrenheter. Vi vill ha en "standard", alltså samma kommunikation med alla plattformar. Vi diskuterade löst t ex I2C och SPI. Ska försöka ha ett möte snart med representant från varje grupp.
*** Oklarheter 
    - Hur stort område skall vi täcka?
    - Vilken upplösning behövs?
    - Vad har vi för budget?
    - Hur många moduler ska vi bygga? Jag lutar åt 4, en för varje plattform, samt en i backup/för testning. Täcker budgeten detta?
*** Gå vidare
    Vi ska imorgon träffa Tommy (Andersson) och diskutera olika möjligheter. Efter detta tänker vi oss att vi kan bestämma oss för hur vi går fram.
** 2017-04-04
   Vi hade möte med Tommy, se [[./Tommy2017-04-04.html][anteckningar]]
** 2017-04-05
   - Vi skrev klart planeringsdokumenten - ett Ganntdiagram, ansvarsschema och milstolpedokument
   - Vi gjorde en preliminär backlog för projektet. Vi diskuterade fram alla de små tasks vi behöver utföra för att klara projektet. Bild av backlogg: [[./bilder/backlog2017-04-05.pdf][länk]]
** 2017-04-07
   - Vi återkom till planeringsdokumenten och gjorde färdigt dessa och lämnade in dem
   - Vi började sammanställa vår research till en förstudie som ska ingå i rapporten 
** 2017-04-10 
   - Jag byggde ihop en liten lysdiodsrigg som vi kan använda till att testa opencv
   - Gjorde research på seriell kommunikation, samt pratade informellt med plattformsgrupperna
     - SPI verkar lättare än tex I2C, samt att arduinokorten har dedikerade headers
     - Det verkar som att plattformsgrupperna kommer kommunicera med robotarmarna över SPI, och att vi då kommer ha en gemensam buss
** 2017-04-11
   Det var föreläsning om teknisk problemlösning på förmiddagen, och gruppseminarium kopplat till detta på eftermiddagen. Vi är lite frustrerade i gruppen då det som togs upp på föreläsningen är sådant vi redan utrett i vår förstudie. Men vi kom fram till att det finns ett värde dels i att faktiskt noggrant och systematiskt gå igenom problemformuleringen, dels att omvärdera sina tidigare slkutsatser och se dem i ett nytt ljus. Vi producerade ett dokument med kravspecifikation, som vi nog kommer inkludera i eller bifoga till rapporten. 
** 2017-04-12
   Jag arbetade med geometrin och formlerna för att överföra bildkoordinater vi får ut från opencv till rumskoordinater i banan som roboten kör på. Metoden för detta finns [[./Koordinatmappning.org][här]]
** 2017-04-13
   - Vi hade möte med representanter från plattformsgrupperna, integrationsgruppen, och jag och Gustaf från positioneringsgruppen. Vi la fram våra två lösningar, och plattformsgrupperna verkade köpa vårt koncept med antingen två leds eller två micar på roboten som vi bestämmer positionen mot. Hur de ska monteras och vems ansvar detta är är en öppen fråga. Vi diskuterade också hur kommunikationen mellan de olika inbyggda systemen på roboten ska kommunicera. Vi bestämde oss för att undersöka SPI, som har de fördelarna att vi kan köra all kommunikation över en gemensam buss för alla enheter, samt att det finns stöd på bla arduino due för DMA, alltså att det finns dedikerad kontroller för SPI, så att ett huvudprogram med tex RTOS inte behöver ha ansvar för kommunikationen. Vi bestämde att integrationsgruppen ska undersöka om vi kan koppla samman 5 enheter på en buss.
   - Jag började arbeta på pythonkoden för koordinatmappningen, i filen coordmapping.py. Jag experimenterade med numpy, och konstaterade att numpy.multiply inte är matrismultiplikation, utan elementvis multiplikation. För matrismultiplikation används numpy.matmul.
** 2017-04-17
   Första fälttestet på Niagara. Vi mätte upp en rektangulär bana på golvet i Niagara med /perfekta/ räta vinklar, som vi fick fram genom att mäta upp 3-4-5-trianglar, samt satte ut ett antal testpunkter. Vi fotade sedan detta från två olika vinklar. Rakt ovanifrån två trappor upp i Niagara är den mest lovande vinkeln. Jag antecknade koordinaterna för testpunkterna relativt hörnen i [[./niagara2017-04-17.html][detta dokument]]. 
** 2017-04-22
   Egentligen inte en arbetsdag, men jag byggde en ställning eller rigg för att på ett säkert sätt kunna ha den kamera vi ska använda en bit ut från kanten två våningar upp på Niagara. Detta för att den ska komma så nära mitt över banan som möjligt. Konstruktionen är i träreglar med säkerhetslina
** 2017-04-23
   Fälttest på Niagara. Vi testade flera saker
   - Om vårt opencv-program kunde identifiera en lysdiod med kameran på tredje våningen
   - Om vi kunde ha kameran ut över kanten och ca en meter ut, för att kunna filma ner på bottenplan mer eller mindre rakt uppifrån
   - Om vi kunde få ut koordinater live via opencv och kunna mappa dem till det koordinatsystem vi definierat på golvet med hjälp av den mappningskod jag skrivit i python
   - Hur noggrant systemet är
   Resultatet var genomgående lyckat, med lite justeringar kunde vi identifiera lysdioder, och även liveuppdateringen fungerade. Kameran var stabil i den rigg jag byggt. Noggrannheten var mer problematiskt - koordinater i y-led hade en felmarginal på under 3cm, men i x-led var felmarginalen upp till 20cm, vilket vi inte anser godtagbart. Vi identifierade ett skäl till detta, att om dioden är en bit över marken blir felet större, vilket är rimligt. Detta planerar jag att korrigera för med lite mer avancerad geometri, där vi identifierar kamerans position bland annat. Detta verkar dock inte lösa hela felet. Vi tror att om vi kartlägger hur stort felet är på olika platser på banan kan vi i koden kompensera för detta och komma ner under 10cm felmarginal med opencv-metoden.
** 2017-04-24
   Idag utvärderade vi fälttestet från igår. Annars hände ingenting
** 2017-04-25
   Föreläsning om testning på förmiddagen. På eftermiddagen hade vi gruppseminarium där vi fastställde en kravspecifikation och började skriva testfall
** 2017-04-27
   - På förmiddagen satt jag och Anton och gick igenom rapporten inför inlämning till M2. Vi har en hel del skrivet material att arbeta med, som vi framställt till största delen på seminarierna. Problemet blir att få ihop en rapport som går att läsa utan att ha tagit del av seminarieinstruktionerna. Just nu känns texten mest som ett svar på frǻgor, inte en fristående text. Jag tror inte att vi kommer hinna skriva om allt det till M2-inlämningen, det får nog vänta till slutinlämningen.
   - På eftermiddagen renskrev jag en del av rapporten utifrån det vi gått igenom på förmiddagen. Det blev inte en stor omskrivning som jag tror krävs till en slutinlämning, utan jag fokuserade mest på att ta bort en del duplikation, städa upp lite språkligt, och klargöra vissa delar.
